import cv2
import numpy as np
import matplotlib.pyplot as plt
import json
import os
import sys

# Helper Function to load descriptor data from JSON
def load_descriptor_data_from_json(json_path):
    """
    Loads keypoints and descriptors from a JSON file generated by SIFT, SURF, or ORB scripts.
    Returns: keypoints (list of cv2.KeyPoint), descriptors (np.ndarray), tool_name (str), original_image_path (str), descriptor_dim (int)
    """
    try:
        with open(json_path, 'r') as f:
            data = json.load(f)

        tool_name = data.get('tool', 'UNKNOWN').upper() # Get tool name (SIFT, SURF, ORB)

        keypoints_data = data['keypoints']
        descriptors_list = [kp_data['descriptor'] for kp_data in keypoints_data]

        keypoints = []
        for kp_data in keypoints_data:
            keypoints.append(cv2.KeyPoint(
                x=float(kp_data['x']),
                y=float(kp_data['y']),
                size=float(kp_data['size']),
                angle=float(kp_data['angle']),
                response=float(kp_data['response']),
                octave=int(kp_data['octave']),
                class_id=int(kp_data['class_id'])
            ))

        # Determine descriptor dtype and dimension based on tool
        descriptor_dim = data.get("descriptor_dim", 0) # Try to get dimension from JSON metadata
        if tool_name in ["SIFT", "SURF"]:
            descriptors = np.array(descriptors_list, dtype=np.float32)
            if descriptor_dim == 0: descriptor_dim = 128 # Default for SIFT/SURF if not in JSON
        elif tool_name == "ORB":
            descriptors = np.array(descriptors_list, dtype=np.uint8)
            if descriptor_dim == 0: descriptor_dim = 32 # Default for ORB if not in JSON (ORB can be 32 or 64)
        else:
            raise ValueError(f"Unsupported descriptor tool type: '{tool_name}'. Descriptors cannot be loaded correctly.")

        original_image_path = data['image']['original_path']

        # Ensure descriptors are not empty, return empty array with correct shape if so
        if not descriptors_list:
            print(f"[WARNING] No descriptors found in {os.path.basename(json_path)}. Returning empty descriptor array.")
            descriptors = np.empty((0, descriptor_dim), dtype=descriptors.dtype)


        return keypoints, descriptors, tool_name, original_image_path, descriptor_dim

    except FileNotFoundError:
        print(f"[ERROR] JSON file not found: {json_path}")
        sys.exit(1)
    except json.JSONDecodeError:
        print(f"[ERROR] Error decoding JSON from: {json_path}. Check file format.")
        sys.exit(1)
    except KeyError as e:
        print(f"[ERROR] Missing required key '{e}' in JSON data from {os.path.basename(json_path)}. Please ensure JSON structure is correct.")
        sys.exit(1)
    except ValueError as e:
        print(f"[ERROR] Data conversion error in {os.path.basename(json_path)}: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"[ERROR] An unexpected error occurred while loading features from {os.path.basename(json_path)}: {e}")
        sys.exit(1)


# --- Configuration ---
# PATHs ไปยังไฟล์ JSON ของคุณ
json_path_img1 = "/Users/pop/Desktop/project_n2n/orb_output/BallA_orb_output.json" # เปลี่ยน Path ให้ถูกต้อง
json_path_img2 = "/Users/pop/Desktop/project_n2n/orb_output/BallB_orb_output.json" # เปลี่ยน Path ให้ถูกต้อง

# --- Load Descriptor Data from JSON ---
print(f"[INFO] Loading data from {os.path.basename(json_path_img1)}...")
kp1, des1, tool1, original_img_path1, dim1 = load_descriptor_data_from_json(json_path_img1)
print(f"[INFO] Image 1 ({tool1}): {len(kp1)} keypoints, Descriptors shape: {des1.shape}")

print(f"[INFO] Loading data from {os.path.basename(json_path_img2)}...")
kp2, des2, tool2, original_img_path2, dim2 = load_descriptor_data_from_json(json_path_img2)
print(f"[INFO] Image 2 ({tool2}): {len(kp2)} keypoints, Descriptors shape: {des2.shape}")

# --- Validate that both JSONs are from the same tool type (CRUCIAL for matching) ---
if tool1 != tool2:
    print(f"\n[ERROR] Descriptor type mismatch! Image 1 is '{tool1}', Image 2 is '{tool2}'.")
    print("        BFMatcher requires both sets of descriptors to be generated by the SAME algorithm (e.g., SIFT-SIFT, ORB-ORB).")
    print("        Please ensure you run feature extraction with the same tool for both images.")
    sys.exit(1) # Exit if tools don't match, as direct matching is not reliable

# --- Check if enough keypoints exist for matching ---
if len(kp1) == 0 or len(kp2) == 0 or des1.shape[0] == 0 or des2.shape[0] == 0:
    print("[ERROR] Not enough keypoints or descriptors to perform matching. Please check your input JSON files.")
    sys.exit(1)

# --- Determine BFMatcher normType based on the tool ---
norm_type = None
norm_type_str = ""
if tool1 in ["SIFT", "SURF"]:
    norm_type = cv2.NORM_L2 # L2_NORM (Euclidean distance) for floating-point descriptors
    norm_type_str = "L2"
    print(f"\n[INFO] Using BFMatcher with cv2.NORM_L2 (Euclidean distance) for '{tool1}' descriptors.")
elif tool1 == "ORB":
    norm_type = cv2.NORM_HAMMING # HAMMING_NORM (Hamming distance) for binary descriptors
    norm_type_str = "HAMMING"
    print(f"\n[INFO] Using BFMatcher with cv2.NORM_HAMMING (Hamming distance) for '{tool1}' descriptors.")
else:
    # This case should ideally be caught by ValueError in load_descriptor_data_from_json
    print(f"[ERROR] Unsupported descriptor tool type: '{tool1}'. Cannot proceed with matching.")
    sys.exit(1)

# --- Create BFMatcher ---
# For ORB, crossCheck=True is often preferred for more robust matches directly.
# For SIFT/SURF, knnMatch + Lowe's Ratio Test (crossCheck=False) is common.
use_cross_check = True if tool1 == "ORB" else False

bf_matcher = cv2.BFMatcher(norm_type, crossCheck=use_cross_check)
print(f"[INFO] BFMatcher created with normType={norm_type_str} and crossCheck={use_cross_check}.")


# --- Perform Matching ---
good_matches = []
raw_matches = [] # To store all matches before any filtering (for metadata)
knn_k_value = None
lowes_ratio_threshold = None

try:
    if use_cross_check:
        print("[INFO] Performing direct matching with crossCheck=True...")
        matches = bf_matcher.match(des1, des2)
        raw_matches = matches # In crossCheck, all matches are "raw" and "good" initially
        good_matches = sorted(matches, key=lambda x: x.distance) # Sort by distance for visualization

    else: # For SIFT/SURF, use knnMatch and Lowe's Ratio Test
        print("[INFO] Performing knnMatch (k=2) and applying Lowe's Ratio Test...")
        knn_k_value = 2 # Fixed for Lowe's Ratio Test
        
        # Ensure that des1 and des2 have enough rows (keypoints) to perform knnMatch
        if des1.shape[0] < knn_k_value or des2.shape[0] < knn_k_value:
            print(f"[WARNING] Not enough descriptors for knnMatch(k={knn_k_value}). Falling back to no matches.")
            matches = [] # No matches if knnMatch cannot be performed properly
        else:
            matches = bf_matcher.knnMatch(des1, des2, k=knn_k_value)
            raw_matches = matches # Store raw knnMatch results

            # Apply Lowe's Ratio Test (common for SIFT/SURF)
            lowes_ratio_threshold = 0.75 # A common threshold for SIFT/SURF

            for m, n in matches:
                if m.distance < lowes_ratio_threshold * n.distance:
                    good_matches.append(m)
            good_matches = sorted(good_matches, key=lambda x: x.distance)

except cv2.error as e:
    print(f"[ERROR] OpenCV matching error: {e}")
    print("        This might indicate incompatible descriptor dimensions or other issues with input data.")
    good_matches = [] # Clear matches if error occurs
    raw_matches = []
except Exception as e:
    print(f"[ERROR] An unexpected error occurred during matching: {e}")
    good_matches = [] # Clear matches if error occurs
    raw_matches = []


print(f"[INFO] Total good matches found: {len(good_matches)}")
print(f"[INFO] Total raw matches (before filtering/sorting for knnMatch): {len(raw_matches)}")

# --- Load Original Images for Visualization ---
try:
    img1_orig = cv2.imread(original_img_path1, cv2.IMREAD_COLOR) # Load as color
    img2_orig = cv2.imread(original_img_path2, cv2.IMREAD_COLOR) # Load as color

    if img1_orig is None:
        print(f"[ERROR] Could not load original image 1 for visualization: {original_img_path1}")
    if img2_orig is None:
        print(f"[ERROR] Could not load original image 2 for visualization: {original_img_path2}")

    if img1_orig is not None and img2_orig is not None:
        # Resize images for better visualization if they are too large
        max_dim = 1000 # Max width or height for display
        if img1_orig.shape[0] > max_dim or img1_orig.shape[1] > max_dim:
            scale_factor1 = max_dim / max(img1_orig.shape[0], img1_orig.shape[1])
            img1_orig = cv2.resize(img1_orig, (int(img1_orig.shape[1] * scale_factor1), int(img1_orig.shape[0] * scale_factor1)))

        if img2_orig.shape[0] > max_dim or img2_orig.shape[1] > max_dim:
            scale_factor2 = max_dim / max(img2_orig.shape[0], img2_orig.shape[1])
            img2_orig = cv2.resize(img2_orig, (int(img2_orig.shape[1] * scale_factor2), int(img2_orig.shape[0] * scale_factor2)))

        # Draw matches
        num_matches_to_draw = min(200, len(good_matches)) # Draw up to 200 matches or all if less
        print(f"[INFO] Drawing top {num_matches_to_draw} matches for visualization...")

        img_matches_vis = cv2.drawMatches(img1_orig, kp1, img2_orig, kp2,
                                         good_matches[:num_matches_to_draw], None,
                                         flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)

        plt.figure(figsize=(18, 10)) # Wider figure for two images side by side
        plt.imshow(cv2.cvtColor(img_matches_vis, cv2.COLOR_BGR2RGB))
        plt.title(f"{tool1} Matches ({len(good_matches)} good matches)")
        plt.axis('off')
        plt.show()
    else:
        print("[WARNING] Skipping visualization because one or both original images could not be loaded.")

except FileNotFoundError as e:
    print(f"[WARNING] Could not load original images for visualization: {e}. Skipping visualization.")
except Exception as e:
    print(f"[ERROR] An unexpected error occurred during visualization: {e}. Skipping visualization.")


# --- Outputting Matches Data (for N2N Node) ---
output_json_dir = "/Users/pop/Desktop/project_n2n/bfmatcher_outputs" # กำหนดโฟลเดอร์สำหรับ output JSON
os.makedirs(output_json_dir, exist_ok=True) # ตรวจสอบให้แน่ใจว่าโฟลเดอร์มีอยู่

matches_output_data = []
for m in good_matches:
    matches_output_data.append({
        "queryIdx": m.queryIdx,
        "trainIdx": m.trainIdx,
        "distance": round(m.distance, 4)
    })

# สร้างชื่อไฟล์ output ให้ชัดเจนและเป็นเอกลักษณ์
img1_base = os.path.basename(original_img_path1).split('.')[0]
img2_base = os.path.basename(original_img_path2).split('.')[0]
output_json_name = f"{img1_base}_vs_{img2_base}_{tool1.lower()}_bf_matches_detail.json" # เพิ่ม _detail เพื่อให้แยกจากเวอร์ชันเก่า
output_json_path = os.path.join(output_json_dir, output_json_name)

try:
    with open(output_json_path, 'w') as f:
        json.dump({
            "matching_tool": "BFMatcher",
            "tool_version": {
                "opencv": cv2.__version__,
                "python": sys.version.split()[0]
            },
            "bfmatcher_parameters_used": {
                "norm_type": norm_type_str,
                "cross_check": use_cross_check,
                "knn_k_value": knn_k_value, 
                "lowes_ratio_threshold": lowes_ratio_threshold 
            },
            "input_features_details": {
                "image1": {
                    "original_path": original_img_path1,
                    "file_name": os.path.basename(original_img_path1),
                    "feature_tool": tool1,
                    "num_keypoints": len(kp1),
                    "descriptor_shape": list(des1.shape) # Convert tuple to list for JSON
                },
                "image2": {
                    "original_path": original_img_path2,
                    "file_name": os.path.basename(original_img_path2),
                    "feature_tool": tool2,
                    "num_keypoints": len(kp2),
                    "descriptor_shape": list(des2.shape) # Convert tuple to list for JSON
                }
            },
            "matching_statistics": {
                "num_raw_matches": len(raw_matches), # Number of matches before filtering (e.g., before Lowe's Ratio Test)
                "num_good_matches": len(good_matches)
            },
            "matches": matches_output_data # The list of good matches with queryIdx, trainIdx, distance
        }, f, indent=4)
    print(f"\n[INFO] Detailed matching results saved to: {output_json_path}")
    print("[INFO] Example of first 5 good matches:")
    print(json.dumps(matches_output_data[:5], indent=4))
except IOError as e:
    print(f"[ERROR] Failed to save detailed matching JSON: {e}")

print("\n[INFO] BFMatcher process completed.")
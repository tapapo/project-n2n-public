# server/algos/alignment/AffineTransformEstimation.py
import os
import cv2
import json
import numpy as np
from typing import Dict, Any

from ...cache_utils import make_cache_key, ensure_dir


def run(
    match_json_path: str,
    out_root: str,
    model: str = "affine",                # "affine" (6 DOF) | "partial" (similarity)
    warp_mode: str = "image2_to_image1",  # "image2_to_image1" | "image1_to_image2"
    blend: bool = False,
    ransac_thresh: float = 3.0,
    confidence: float = 0.99,
    refine_iters: int = 10,
) -> Dict[str, Any]:
    """
    üß≠ Affine Transform Estimation
    =========================================
    ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏™‡πâ‡∏ô (Linear Transformation)
    ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏†‡∏≤‡∏û 2 ‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å‡∏à‡∏∏‡∏î‡∏Ñ‡∏π‡πà (matched_points)

    ‚úÖ ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏Å‡∏±‡∏ö matcher JSON ‡∏ó‡∏µ‡πà‡∏°‡∏µ matched_points
    ‚úÖ ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö 2 ‡πÇ‡∏´‡∏°‡∏î:
        - model="affine"   ‚Üí cv2.estimateAffine2D()  (6 DOF)
        - model="partial"  ‚Üí cv2.estimateAffinePartial2D() (similarity transform)
    ‚úÖ ‡πÉ‡∏ä‡πâ RANSAC ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏±‡∏î outliers

    Output:
        <out_root>/features/affinetransformestimation_outputs/affine_<hash>.jpg
        <out_root>/features/affinetransformestimation_outputs/affine_<hash>.json
    """

    # ---------- ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° directory ----------
    out_dir = os.path.join(out_root, "features", "affinetransformestimation_outputs")
    ensure_dir(out_dir)

    # ---------- ‡∏™‡∏£‡πâ‡∏≤‡∏á hash key ----------
    key = make_cache_key(
        "AFFINE_TRANSFORM",
        files=[match_json_path],
        params={
            "model": model,
            "warp_mode": warp_mode,
            "blend": blend,
            "ransac_thresh": ransac_thresh,
            "confidence": confidence,
            "refine_iters": refine_iters,
        },
    )
    stem = f"affine_{key}"
    out_img = os.path.join(out_dir, f"{stem}.jpg")
    out_json = os.path.join(out_dir, f"{stem}.json")

    # ---------- ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ cache ‡πÄ‡∏î‡∏¥‡∏° ----------
    if os.path.exists(out_img) and os.path.exists(out_json):
        with open(out_json, "r", encoding="utf-8") as f:
            data = json.load(f)
        data.setdefault("output", {})["aligned_image"] = out_img
        data["json_path"] = out_json
        return data

    # ---------- ‡πÇ‡∏´‡∏•‡∏î matcher JSON ----------
    with open(match_json_path, "r", encoding="utf-8") as f:
        match_data = json.load(f)

    try:
        img1_path = match_data["input_features_details"]["image1"]["original_path"]
        img2_path = match_data["input_features_details"]["image2"]["original_path"]
    except Exception:
        raise ValueError("Matcher JSON ‡πÑ‡∏°‡πà‡∏°‡∏µ input_features_details.image{1,2}.original_path")

    matched_points = match_data.get("matched_points")
    if not (matched_points and len(matched_points) >= 3):
        raise ValueError("‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ matched_points ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 3 ‡∏à‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö affine transform")

    pts1 = np.float32([m["pt1"] for m in matched_points]).reshape(-1, 1, 2)
    pts2 = np.float32([m["pt2"] for m in matched_points]).reshape(-1, 1, 2)

    # ---------- ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏Å‡∏≤‡∏£ Affine Transform ----------
    if model.lower() == "partial":
        M, mask = cv2.estimateAffinePartial2D(
            pts2, pts1,
            method=cv2.RANSAC,
            ransacReprojThreshold=ransac_thresh,
            confidence=confidence,
            refineIters=refine_iters,
        )
        model_used = "Similarity Transform (estimateAffinePartial2D)"
    else:
        M, mask = cv2.estimateAffine2D(
            pts2, pts1,
            method=cv2.RANSAC,
            ransacReprojThreshold=ransac_thresh,
            confidence=confidence,
            refineIters=refine_iters,
        )
        model_used = "Full Affine Transform (estimateAffine2D)"

    if M is None:
        raise RuntimeError("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì affine matrix ‡πÑ‡∏î‡πâ")

    inliers = int(mask.sum()) if mask is not None else 0

    # ---------- ‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û ----------
    img1 = cv2.imread(img1_path)
    img2 = cv2.imread(img2_path)
    if img1 is None or img2 is None:
        raise RuntimeError("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡∏†‡∏≤‡∏û‡πÑ‡∏î‡πâ")

    # ---------- Warp ----------
    if warp_mode == "image2_to_image1":
        h, w = img1.shape[:2]
        aligned = cv2.warpAffine(img2, M, (w, h))
        base_for_blend = img1
    else:
        M33 = np.vstack([M, [0, 0, 1]])  # ‡∏ó‡∏≥‡πÄ‡∏õ‡πá‡∏ô 3x3 ‡∏Å‡πà‡∏≠‡∏ô‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏°‡∏ó‡∏£‡∏¥‡∏Å‡∏ã‡πå
        M_inv = np.linalg.inv(M33)[0:2, :]
        h2, w2 = img2.shape[:2]
        aligned = cv2.warpAffine(img1, M_inv, (w2, h2))
        base_for_blend = img2

    if blend:
        if aligned.shape[:2] != base_for_blend.shape[:2]:
            aligned = cv2.resize(aligned, (base_for_blend.shape[1], base_for_blend.shape[0]))
        aligned = cv2.addWeighted(base_for_blend, 0.5, aligned, 0.5, 0)

    # ---------- Save ----------
    cv2.imwrite(out_img, aligned)

    result = {
        "alignment_tool": model_used,
        "tool_version": cv2.__version__,
        "model": model.lower(),
        "warp_mode": warp_mode,
        "blend": blend,
        "ransac_reproj_threshold": ransac_thresh,
        "confidence": confidence,
        "refine_iters": refine_iters,
        "num_inliers": inliers,
        "affine_matrix": M.tolist(),
        "input_images": {"image1": img1_path, "image2": img2_path},
        "inputs": {"match_json": match_json_path},
        "output": {"aligned_image": out_img},
        "cache_key": key,
        "json_path": out_json,
    }

    with open(out_json, "w", encoding="utf-8") as f:
        json.dump(result, f, indent=2, ensure_ascii=False)

    return result